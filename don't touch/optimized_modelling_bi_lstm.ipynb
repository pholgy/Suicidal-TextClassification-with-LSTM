{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras import callbacks\n",
    "from keras.models import Sequential\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "import keras\n",
    "from keras import *\n",
    "from keras.layers import *\n",
    "from pythainlp import word_tokenize\n",
    "from pythainlp.word_vector import *\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from pythainlp import word_vector\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', \n",
    "    patience=8, \n",
    "    min_delta=0.001, \n",
    "    mode='max'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('main_suicidal_data.csv').drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wModel = word_vector.WordVector(model_name=\"thai2fit_wv\").get_model()\n",
    "thai2dict = {}\n",
    "for word in wModel.index_to_key:\n",
    "    thai2dict[word] = wModel[word]\n",
    "thai2vec = pd.DataFrame.from_dict(thai2dict,orient='index')\n",
    "thVocab = thai2vec.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51300\n",
      " (51358, 300)\n"
     ]
    }
   ],
   "source": [
    "ll = len(thai2vec)\n",
    "for vidx in range(ll):\n",
    "    if vidx % 100 == 0:\n",
    "        print('\\r' + str(vidx),end='')\n",
    "    aa = thai2vec.iloc[[vidx]]\n",
    "    ab = aa.values.tolist()\n",
    "    if vidx == 0:\n",
    "        vect = ab\n",
    "    else:\n",
    "        vect = np.vstack((vect,ab))\n",
    "\n",
    "print(\"\\n\", vect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenWord(wordTarget):\n",
    "    wordToken = word_tokenize(wordTarget, engine='attacut')\n",
    "    return wordToken\n",
    "\n",
    "def convWord(cw):\n",
    "    cWord = cw\n",
    "    for ti in range(len(cWord)):\n",
    "        if cWord[ti] == ' ':\n",
    "            cWord[ti] = ''\n",
    "        elif cWord[ti] not in thVocab:\n",
    "            cWord[ti] = ''\n",
    "    return cWord\n",
    "\n",
    "def token2index(t2idx):\n",
    "    w2index = []\n",
    "    for wi in range(len(t2idx)):\n",
    "        if t2idx[wi] in thVocab:\n",
    "            w2index.append(thVocab.index(t2idx[wi]))\n",
    "    return np.array(w2index)\n",
    "\n",
    "def findMaxArray(fma):\n",
    "    maxlen = 0\n",
    "    for mi in range(len(fma)):\n",
    "        nA = len(fma[mi])\n",
    "        if nA > maxlen:\n",
    "            maxlen = nA\n",
    "    return maxlen\n",
    "\n",
    "def fill0in(f0i):\n",
    "    fMax = findMaxArray(f0i)\n",
    "    for fi, ax in enumerate(f0i):\n",
    "        if len(ax) < fMax:\n",
    "            f0i[fi] = np.hstack((ax , np.zeros(fMax-len(ax))))\n",
    "        f0i1 = np.array(f0i)\n",
    "    return f0i1\n",
    "\n",
    "def prepare2train(ipt):\n",
    "    pre2t = []\n",
    "    for pidx in range(len(ipt)):\n",
    "        wp1 = ipt[pidx]\n",
    "        pre2t.append(token2index(convWord(tokenWord(wp1))))\n",
    "    return pre2t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Tweet']\n",
    "X_arr = X.to_list()\n",
    "y = df['Label (Specialist)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = prepare2train(X_arr)\n",
    "y = le.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)\n",
    "X = fill0in(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embed (Embedding)           (None, None, 300)         15407400  \n",
      "                                                                 \n",
      " bidirectional_22 (Bidirecti  (None, None, 128)        186880    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " bidirectional_23 (Bidirecti  (None, 64)               41216     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 24)                1560      \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 24)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 6)                 150       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,637,206\n",
      "Trainable params: 15,637,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(input_dim=51358,output_dim=300,name='embed'))\n",
    "\n",
    "#Layer 2: LSTM layer\n",
    "model.add(Bidirectional(LSTM(64, return_sequences = True)))\n",
    "model.add(Dropout(rate=0.8))\n",
    "#Layer 3: LSTM layer\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dropout(rate=0.8))\n",
    "\n",
    "#Layer 4: Dense layer (Hidden layer)\n",
    "model.add(Dense(24, activation = 'relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "#Layer 5: Output layer\n",
    "model.add(Dense(6, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "opt = SGD(learning_rate=0.001,momentum=0.9,nesterov=True)\n",
    "adam_opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_layer('embed').set_weights([vect])\n",
    "model.get_layer('embed').trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device for operation sequential_9/embed/embedding_lookup: Could not satisfy explicit device specification '' because the node {{colocation_node sequential_9/embed/embedding_lookup}} was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0]. \nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=2 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nUnsortedSegmentSum: GPU CPU \nStridedSlice: GPU CPU \nConst: GPU CPU \nShape: GPU CPU \n_Arg: GPU CPU \nUnique: GPU CPU \nIdentity: GPU CPU \nResourceSparseApplyKerasMomentum: CPU \nResourceGather: GPU CPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  sequential_9_embed_embedding_lookup_90207 (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  sgd_sgd_update_resourcesparseapplykerasmomentum_accum (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  sequential_9/embed/embedding_lookup (ResourceGather) \n  sequential_9/embed/embedding_lookup/Identity (Identity) \n  SGD/SGD/update/Unique (Unique) /job:localhost/replica:0/task:0/device:GPU:0\n  SGD/SGD/update/Shape (Shape) /job:localhost/replica:0/task:0/device:GPU:0\n  SGD/SGD/update/strided_slice/stack (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  SGD/SGD/update/strided_slice/stack_1 (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  SGD/SGD/update/strided_slice/stack_2 (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  SGD/SGD/update/strided_slice (StridedSlice) /job:localhost/replica:0/task:0/device:GPU:0\n  SGD/SGD/update/UnsortedSegmentSum (UnsortedSegmentSum) /job:localhost/replica:0/task:0/device:GPU:0\n  SGD/SGD/update/ResourceSparseApplyKerasMomentum (ResourceSparseApplyKerasMomentum) /job:localhost/replica:0/task:0/device:GPU:0\n\n\t [[{{node sequential_9/embed/embedding_lookup}}]] [Op:__inference_train_function_94372]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/Users/yo/Github/Suicidal-Classification-with-LSTM/don't touch/optimized_modelling_bi_lstm.ipynb Cell 15\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yo/Github/Suicidal-Classification-with-LSTM/don%27t%20touch/optimized_modelling_bi_lstm.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train,y_train,epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m,batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,callbacks\u001b[39m=\u001b[39;49m[early_stopping],validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 58\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     59\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     61\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation sequential_9/embed/embedding_lookup: Could not satisfy explicit device specification '' because the node {{colocation_node sequential_9/embed/embedding_lookup}} was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0]. \nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=2 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nUnsortedSegmentSum: GPU CPU \nStridedSlice: GPU CPU \nConst: GPU CPU \nShape: GPU CPU \n_Arg: GPU CPU \nUnique: GPU CPU \nIdentity: GPU CPU \nResourceSparseApplyKerasMomentum: CPU \nResourceGather: GPU CPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  sequential_9_embed_embedding_lookup_90207 (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  sgd_sgd_update_resourcesparseapplykerasmomentum_accum (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  sequential_9/embed/embedding_lookup (ResourceGather) \n  sequential_9/embed/embedding_lookup/Identity (Identity) \n  SGD/SGD/update/Unique (Unique) /job:localhost/replica:0/task:0/device:GPU:0\n  SGD/SGD/update/Shape (Shape) /job:localhost/replica:0/task:0/device:GPU:0\n  SGD/SGD/update/strided_slice/stack (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  SGD/SGD/update/strided_slice/stack_1 (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  SGD/SGD/update/strided_slice/stack_2 (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  SGD/SGD/update/strided_slice (StridedSlice) /job:localhost/replica:0/task:0/device:GPU:0\n  SGD/SGD/update/UnsortedSegmentSum (UnsortedSegmentSum) /job:localhost/replica:0/task:0/device:GPU:0\n  SGD/SGD/update/ResourceSparseApplyKerasMomentum (ResourceSparseApplyKerasMomentum) /job:localhost/replica:0/task:0/device:GPU:0\n\n\t [[{{node sequential_9/embed/embedding_lookup}}]] [Op:__inference_train_function_94372]"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,epochs=20,batch_size=32,callbacks=[early_stopping],validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device for operation sequential_9/embed/embedding_lookup: Could not satisfy explicit device specification '' because the node {{colocation_node sequential_9/embed/embedding_lookup}} was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0]. \nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=2 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nUnsortedSegmentSum: GPU CPU \nStridedSlice: GPU CPU \nConst: GPU CPU \nShape: GPU CPU \n_Arg: GPU CPU \nUnique: GPU CPU \nIdentity: GPU CPU \nResourceSparseApplyKerasMomentum: CPU \nResourceGather: GPU CPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  sequential_9_embed_embedding_lookup_90207 (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  sgd_sgd_update_resourcesparseapplykerasmomentum_accum (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  sequential_9/embed/embedding_lookup (ResourceGather) \n  sequential_9/embed/embedding_lookup/Identity (Identity) \n  SGD/SGD/update/Unique (Unique) /job:localhost/replica:0/task:0/device:GPU:0\n  SGD/SGD/update/Shape (Shape) /job:localhost/replica:0/task:0/device:GPU:0\n  SGD/SGD/update/strided_slice/stack (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  SGD/SGD/update/strided_slice/stack_1 (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  SGD/SGD/update/strided_slice/stack_2 (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  SGD/SGD/update/strided_slice (StridedSlice) /job:localhost/replica:0/task:0/device:GPU:0\n  SGD/SGD/update/UnsortedSegmentSum (UnsortedSegmentSum) /job:localhost/replica:0/task:0/device:GPU:0\n  SGD/SGD/update/ResourceSparseApplyKerasMomentum (ResourceSparseApplyKerasMomentum) /job:localhost/replica:0/task:0/device:GPU:0\n\n\t [[{{node sequential_9/embed/embedding_lookup}}]] [Op:__inference_train_function_94372]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)\n",
      "\u001b[1;32m/Users/yo/Github/Suicidal-Classification-with-LSTM/don't touch/optimized_modelling_bi_lstm.ipynb Cell 15\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yo/Github/Suicidal-Classification-with-LSTM/don%27t%20touch/optimized_modelling_bi_lstm.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train,y_train,epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m,batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,callbacks\u001b[39m=\u001b[39;49m[early_stopping],validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m)\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n",
      "\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n",
      "\u001b[1;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;32m     57\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n",
      "\u001b[0;32m---> 58\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n",
      "\u001b[1;32m     59\u001b[0m                                       inputs, attrs, num_outputs)\n",
      "\u001b[1;32m     60\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;32m     61\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation sequential_9/embed/embedding_lookup: Could not satisfy explicit device specification '' because the node {{colocation_node sequential_9/embed/embedding_lookup}} was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0]. \n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and supported devices: \n",
      "Root Member(assigned_device_name_index_=2 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
      "UnsortedSegmentSum: GPU CPU \n",
      "StridedSlice: GPU CPU \n",
      "Const: GPU CPU \n",
      "Shape: GPU CPU \n",
      "_Arg: GPU CPU \n",
      "Unique: GPU CPU \n",
      "Identity: GPU CPU \n",
      "ResourceSparseApplyKerasMomentum: CPU \n",
      "ResourceGather: GPU CPU \n",
      "\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
      "  sequential_9_embed_embedding_lookup_90207 (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n",
      "  sgd_sgd_update_resourcesparseapplykerasmomentum_accum (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n",
      "  sequential_9/embed/embedding_lookup (ResourceGather) \n",
      "  sequential_9/embed/embedding_lookup/Identity (Identity) \n",
      "  SGD/SGD/update/Unique (Unique) /job:localhost/replica:0/task:0/device:GPU:0\n",
      "  SGD/SGD/update/Shape (Shape) /job:localhost/replica:0/task:0/device:GPU:0\n",
      "  SGD/SGD/update/strided_slice/stack (Const) /job:localhost/replica:0/task:0/device:GPU:0\n",
      "  SGD/SGD/update/strided_slice/stack_1 (Const) /job:localhost/replica:0/task:0/device:GPU:0\n",
      "  SGD/SGD/update/strided_slice/stack_2 (Const) /job:localhost/replica:0/task:0/device:GPU:0\n",
      "  SGD/SGD/update/strided_slice (StridedSlice) /job:localhost/replica:0/task:0/device:GPU:0\n",
      "  SGD/SGD/update/UnsortedSegmentSum (UnsortedSegmentSum) /job:localhost/replica:0/task:0/device:GPU:0\n",
      "  SGD/SGD/update/ResourceSparseApplyKerasMomentum (ResourceSparseApplyKerasMomentum) /job:localhost/replica:0/task:0/device:GPU:0\n",
      "\n",
      "\t [[{{node sequential_9/embed/embedding_lookup}}]] [Op:__inference_train_function_94372]"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,epochs=20,batch_size=32,callbacks=[early_stopping],validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "def plot_metric(history, metric):\n",
    "    train_metrics = history.history[metric]\n",
    "    val_metrics = history.history['val_'+metric]\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "    plt.plot(epochs, train_metrics)\n",
    "    plt.plot(epochs, val_metrics)\n",
    "    plt.title('Training and validation '+ metric)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_acc = model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(X_test),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('mlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10 | packaged by conda-forge | (main, Feb  1 2022, 21:25:34) \n[Clang 11.1.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "312e11345a26bb658cc76d44d3920b107a1290315a78b9f69927adb21ad3c257"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
