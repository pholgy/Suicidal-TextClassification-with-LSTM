{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras import callbacks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding,LSTM,Dense,Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras import *\n",
    "from keras.layers import *\n",
    "from pythainlp import word_tokenize\n",
    "from pythainlp.word_vector import *\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('main_suicidal_data.csv').drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wModel = get_model()\n",
    "thai2dict = {}\n",
    "for word in wModel.index_to_key:\n",
    "    thai2dict[word] = wModel[word]\n",
    "thai2vec = pd.DataFrame.from_dict(thai2dict,orient='index')\n",
    "thVocab = thai2vec.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = len(thai2vec)\n",
    "for vidx in range(ll):\n",
    "    if vidx % 100 == 0:\n",
    "        print('\\r' + str(vidx),end='')\n",
    "    aa = thai2vec.iloc[[vidx]]\n",
    "    ab = aa.values.tolist()\n",
    "    if vidx == 0:\n",
    "        vect = ab\n",
    "    else:\n",
    "        vect = np.vstack((vect,ab))\n",
    "\n",
    "print(\"\\n\", vect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenWord(wordTarget):\n",
    "    wordToken = word_tokenize(wordTarget, engine='attacut')\n",
    "    return wordToken\n",
    "\n",
    "def convWord(cw):\n",
    "    cWord = cw\n",
    "    for ti in range(len(cWord)):\n",
    "        if cWord[ti] == ' ':\n",
    "            cWord[ti] = ''\n",
    "        elif cWord[ti] not in thVocab:\n",
    "            cWord[ti] = ''\n",
    "    return cWord\n",
    "\n",
    "def token2index(t2idx):\n",
    "    w2index = []\n",
    "    for wi in range(len(t2idx)):\n",
    "        if t2idx[wi] in thVocab:\n",
    "            w2index.append(thVocab.index(t2idx[wi]))\n",
    "    return np.array(w2index)\n",
    "\n",
    "def findMaxArray(fma):\n",
    "    maxlen = 0\n",
    "    for mi in range(len(fma)):\n",
    "        nA = len(fma[mi])\n",
    "        if nA > maxlen:\n",
    "            maxlen = nA\n",
    "    return maxlen\n",
    "\n",
    "def fill0in(f0i):\n",
    "    fMax = findMaxArray(f0i)\n",
    "    for fi, ax in enumerate(f0i):\n",
    "        if len(ax) < fMax:\n",
    "            f0i[fi] = np.hstack((ax , np.zeros(fMax-len(ax))))\n",
    "        f0i1 = np.array(f0i)\n",
    "    return f0i1\n",
    "\n",
    "def prepare2train(ipt):\n",
    "    pre2t = []\n",
    "    for pidx in range(len(ipt)):\n",
    "        wp1 = ipt[pidx]\n",
    "        pre2t.append(token2index(convWord(tokenWord(wp1))))\n",
    "    return pre2t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Tweet']\n",
    "X_arr = X.to_list()\n",
    "y = df['Label (Specialist)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = prepare2train(X_arr)\n",
    "y = le.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)\n",
    "X = fill0in(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vect.shape[0],vect.shape[1],name='embed'))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "opt = SGD(lr=0.1)\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_layer('embed').set_weights([vect])\n",
    "model.get_layer('embed').trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('accuracy')>0.95):\n",
    "      self.model.stop_training = True\n",
    "      print(\"\\nCallback Accuracy มากกว่า 95%!\")\n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train,epochs=30,batch_size=16,callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_acc = model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(X_test),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try it with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier() \n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_rf_not_tuning = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_rf_not_tuning))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in range(200,2000,200)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=0, random_state=42, n_jobs = -1)\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_random.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tuned = RandomForestClassifier(bootstrap=False, max_depth=30, max_features='auto',\n",
    "                       n_estimators=200)\n",
    "rf_tuned.fit(X_train, y_train)\n",
    "y_pred_rf_tuned = rf_tuned.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_rf_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('mlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "312e11345a26bb658cc76d44d3920b107a1290315a78b9f69927adb21ad3c257"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
